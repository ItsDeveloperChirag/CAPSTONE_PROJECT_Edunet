{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ibm_watsonx_ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaItygbTjHeq",
        "outputId": "4c6dc65e-73ab-4f18-d6a2-cd1f1ddb92ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ibm_watsonx_ai\n",
            "  Downloading ibm_watsonx_ai-1.3.32-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (2.32.3)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (2.5.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (2025.7.14)\n",
            "Collecting lomond (from ibm_watsonx_ai)\n",
            "  Downloading lomond-0.3.3-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (25.0)\n",
            "Collecting ibm-cos-sdk<2.15.0,>=2.12.0 (from ibm_watsonx_ai)\n",
            "  Downloading ibm_cos_sdk-2.14.3.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from ibm_watsonx_ai) (5.5.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm_watsonx_ai) (0.16.0)\n",
            "Collecting ibm-cos-sdk-core==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai)\n",
            "  Downloading ibm_cos_sdk_core-2.14.3.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai)\n",
            "  Downloading ibm_cos_sdk_s3transfer-2.14.3.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai) (2.9.0.post0)\n",
            "Collecting requests (from ibm_watsonx_ai)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm_watsonx_ai) (3.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm_watsonx_ai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm_watsonx_ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm_watsonx_ai) (4.14.1)\n",
            "Downloading ibm_watsonx_ai-1.3.32-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.3-py3-none-any.whl size=77232 sha256=015314716e4aeb46b18ee6a4f2c0c7aeca60bf09e187096416aca93b57f0b21f\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/fa/85/9a1004ed234750540a7a90f34000bc1208e723f3613eaafc2b\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.3-py3-none-any.whl size=662101 sha256=69869410176b7f1667183ff48beaea8eec5d51bd385f1dd002fced4d4e2032f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/25/ac/fa87dd4aeda7eba0f3e7e891c52f9c92c8b2ea49963119d9df\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.3-py3-none-any.whl size=90203 sha256=c972227573a5643c917a41c5cc0c1b0e024ae1017e38a421bfecb90502974d0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/03/6f/e85bbf1471a809e7892239f69458cef2cd69ee38fb543339c8\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: requests, lomond, jmespath, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, ibm_watsonx_ai\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm_watsonx_ai-1.3.32 jmespath-1.0.1 lomond-0.3.3 requests-2.32.4\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hT7ZkLbi9M8",
        "outputId": "a31f51de-9782-4d8c-9dc1-a970751fd341"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ibm_watsonx_ai import APIClient, Credentials\n",
        "import getpass\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        ")\n",
        "#IWjtMQpCrJT_SE2MJPFBh99w4v7b_q33Athk5FTi4oe3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your api key (hit enter): ··········\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "THVVkmCti9M-"
      },
      "cell_type": "code",
      "source": [
        "client = APIClient(credentials)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "difwV5sbi9M-",
        "outputId": "6701436f-5180-42b6-dd64-4f54ca304d09"
      },
      "cell_type": "code",
      "source": [
        "space_id = \"a6bb01cd-7c90-4b47-b413-aa8d00d3c949\"\n",
        "client.set.default_space(space_id)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "s-ahFKK9i9M_"
      },
      "cell_type": "code",
      "source": [
        "source_project_id = \"38879a89-7193-4db0-bc96-a40b01283ee4\"\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XvgrPwDi9NA"
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"space_id\": space_id,\n",
        "}\n",
        "\n",
        "def gen_ai_service(context, params = params, **custom):\n",
        "    # import dependencies\n",
        "    from langchain_ibm import ChatWatsonx\n",
        "    from ibm_watsonx_ai import APIClient\n",
        "    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
        "    from langchain_core.messages import AIMessage, HumanMessage\n",
        "    from langgraph.checkpoint.memory import MemorySaver\n",
        "    from langgraph.prebuilt import create_react_agent\n",
        "    import json\n",
        "    import requests\n",
        "\n",
        "    model = \"ibm/granite-3-3-8b-instruct\"\n",
        "\n",
        "    service_url = \"https://us-south.ml.cloud.ibm.com\"\n",
        "    # Get credentials token\n",
        "    credentials = {\n",
        "        \"url\": service_url,\n",
        "        \"token\": context.generate_token()\n",
        "    }\n",
        "\n",
        "    # Setup client\n",
        "    client = APIClient(credentials)\n",
        "    space_id = params.get(\"space_id\")\n",
        "    client.set.default_space(space_id)\n",
        "\n",
        "\n",
        "    def decrypt_tool_secrets(secrets):\n",
        "        url = \"https://api.dataplatform.cloud.ibm.com\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f'Bearer {context.generate_token()}'\n",
        "        }\n",
        "\n",
        "        body = {\n",
        "            \"secrets\": secrets,\n",
        "            \"space_id\": space_id\n",
        "        }\n",
        "\n",
        "        response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/secret/decrypt', headers=headers, json=body)\n",
        "\n",
        "        return response.json().get(\"secrets\")\n",
        "\n",
        "    encrypted_secrets = [\n",
        "        \"gcm-agent-tools-qHi31me0EfjVZVuGAnau05GBdpyvCVyV:22Ey/IVF7iuVwtXqQFeNZg==;onvmpQr2LOx6ReFy4FIM3w==:x5yeovyHOtSaMFUWg9/OuaYqD1XGT92NC05529T0LmSfs7lr2pReI62RI4Q=\"\n",
        "    ]\n",
        "    decrypted_secrets = decrypt_tool_secrets(encrypted_secrets)\n",
        "\n",
        "    TavilySearch_apiKey = decrypted_secrets[0]\n",
        "\n",
        "\n",
        "    def create_chat_model(watsonx_client):\n",
        "        parameters = {\n",
        "            \"frequency_penalty\": 0,\n",
        "            \"max_tokens\": 2000,\n",
        "            \"presence_penalty\": 0,\n",
        "            \"temperature\": 0,\n",
        "            \"top_p\": 1\n",
        "        }\n",
        "\n",
        "        chat_model = ChatWatsonx(\n",
        "            model_id=model,\n",
        "            url=service_url,\n",
        "            space_id=space_id,\n",
        "            params=parameters,\n",
        "            watsonx_client=watsonx_client,\n",
        "        )\n",
        "        return chat_model\n",
        "\n",
        "\n",
        "    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
        "        from langchain_core.tools import StructuredTool\n",
        "        utility_agent_tool = Toolkit(\n",
        "            api_client=api_client\n",
        "        ).get_tool(tool_name)\n",
        "\n",
        "        tool_description = utility_agent_tool.get(\"description\")\n",
        "\n",
        "        if (kwargs.get(\"tool_description\")):\n",
        "            tool_description = kwargs.get(\"tool_description\")\n",
        "        elif (utility_agent_tool.get(\"agent_description\")):\n",
        "            tool_description = utility_agent_tool.get(\"agent_description\")\n",
        "\n",
        "        tool_schema = utility_agent_tool.get(\"input_schema\")\n",
        "        if (tool_schema == None):\n",
        "            tool_schema = {\n",
        "                \"type\": \"object\",\n",
        "                \"additionalProperties\": False,\n",
        "                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "                \"properties\": {\n",
        "                    \"input\": {\n",
        "                        \"description\": \"input for the tool\",\n",
        "                        \"type\": \"string\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "        def run_tool(**tool_input):\n",
        "            query = tool_input\n",
        "            if (utility_agent_tool.get(\"input_schema\") == None):\n",
        "                query = tool_input.get(\"input\")\n",
        "\n",
        "            results = utility_agent_tool.run(\n",
        "                input=query,\n",
        "                config=params\n",
        "            )\n",
        "\n",
        "            return results.get(\"output\")\n",
        "\n",
        "        return StructuredTool(\n",
        "            name=tool_name,\n",
        "            description = tool_description,\n",
        "            func=run_tool,\n",
        "            args_schema=tool_schema\n",
        "        )\n",
        "\n",
        "\n",
        "    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
        "        from langchain_core.tools import StructuredTool\n",
        "        import ast\n",
        "\n",
        "        def call_tool(**kwargs):\n",
        "            tree = ast.parse(tool_code, mode=\"exec\")\n",
        "            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
        "            function_name = custom_tool_functions[0].name\n",
        "            compiled_code = compile(tree, 'custom_tool', 'exec')\n",
        "            namespace = tool_params if tool_params else {}\n",
        "            exec(compiled_code, namespace)\n",
        "            return namespace[function_name](**kwargs)\n",
        "\n",
        "        tool = StructuredTool(\n",
        "            name=tool_name,\n",
        "            description = tool_description,\n",
        "            func=call_tool,\n",
        "            args_schema=tool_schema\n",
        "        )\n",
        "        return tool\n",
        "\n",
        "    def create_custom_tools():\n",
        "        custom_tools = []\n",
        "\n",
        "\n",
        "    def create_tools(inner_client, context):\n",
        "        tools = []\n",
        "\n",
        "        config = None\n",
        "        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n",
        "        config = {\n",
        "        }\n",
        "        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n",
        "        config = {\n",
        "            \"maxResults\": 5\n",
        "        }\n",
        "        tools.append(create_utility_agent_tool(\"Wikipedia\", config, inner_client))\n",
        "        config = {\n",
        "            \"maxResults\": 10,\n",
        "            \"apiKey\": TavilySearch_apiKey\n",
        "        }\n",
        "        tools.append(create_utility_agent_tool(\"TavilySearch\", config, inner_client))\n",
        "        config = {\n",
        "        }\n",
        "        tools.append(create_utility_agent_tool(\"WebCrawler\", config, inner_client))\n",
        "        return tools\n",
        "\n",
        "    def create_agent(model, tools, messages):\n",
        "        memory = MemorySaver()\n",
        "        instructions = \"\"\"# Notes\n",
        "- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n",
        "- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\n",
        "You are a cognitive AI-powered assistant built on IBM’s Watsonx platform, designed to streamline research and data analysis. It leverages advanced natural language processing and machine learning to understand complex queries, gather relevant information from diverse sources, and present insights in an easy-to-understand format. The agent can summarize large volumes of data, detect trends, suggest research directions, and integrate with enterprise datasets or APIs. Ideal for academic, scientific, and market research, it helps reduce time spent on manual searching while improving the accuracy and depth of findings.\n",
        "Phase 1: Query Analysis and Planning\n",
        "1. Receive and Deconstruct the User Query\n",
        "\n",
        "Receive: The Orchestration Agent receives the user's initial request.\n",
        "\n",
        "Deconstruct: Analyze the query to identify its core components:\n",
        "\n",
        "Subject: What is the central topic? (e.g., \\\"sustainable energy,\\\" \\\"AI in medicine\\\").\n",
        "\n",
        "Scope: What are the boundaries of the research? (e.g., \\\"latest research,\\\" \\\"economic impact,\\\" \\\"technological challenges\\\").\n",
        "\n",
        "Output Format: What does the user expect? (e.g., \\\"summary,\\\" \\\"report,\\\" \\\"list of papers\\\").\n",
        "\n",
        "2. Formulate a Strategic Research Plan\n",
        "\n",
        "Generate a Plan: Based on the deconstructed query, create a step-by-step plan using the Planner Agent. This plan must be a logical sequence of actions to fulfill the request.\n",
        "\n",
        "Example Plan:\n",
        "\n",
        "Step 1: Conduct a broad search for recent academic papers and articles on the subject.\n",
        "\n",
        "Step 2: Filter the search results based on relevance, publication date (e.g., last 2-3 years), and source credibility.\n",
        "\n",
        "Step 3: For each highly relevant source, extract key findings, methodologies, and conclusions.\n",
        "\n",
        "Step 4: Synthesize the extracted information, identifying common themes and contrasting viewpoints.\n",
        "\n",
        "Step 5: Structure the findings into a clear, concise, and well-organized final report.\n",
        "\n",
        "Phase 2: Information Gathering and Retrieval\n",
        "1. Execute the Search Action (Research Assistant Agent)\n",
        "\n",
        "Command: Use the generated plan to trigger search actions.\n",
        "\n",
        "Tools:\n",
        "\n",
        "Web Search: Use a live search tool to find the most current and publicly available information.\n",
        "\n",
        "Knowledge Base Search: Query the internal vector database (part of the RAG system) for relevant, pre-indexed documents, research papers, and reports.\n",
        "\n",
        "Strategy: Prioritize searches that are specific and focused to avoid irrelevant results. Use multiple search queries if the initial results are insufficient.\n",
        "\n",
        "2. Data Extraction and Filtering\n",
        "\n",
        "Extraction: For each search result, extract the title, author, publication date, abstract, key findings, and conclusion. Use the Summarizer Agent to quickly identify the main points of each source.\n",
        "\n",
        "Filtering: Apply the filtering criteria from the plan. Discard any sources that are outdated, from unreliable outlets, or are not directly relevant to the user's scope.\n",
        "\n",
        "Verification: Cross-reference information where possible. If a major finding is mentioned in one paper, see if it is supported or challenged by others.\n",
        "\n",
        "Phase 3: Synthesis and Validation\n",
        "1. Consolidate Information (Summarizer Agent)\n",
        "\n",
        "Synthesize: Group the extracted key findings by topic or theme. For example, if the topic is \\\"AI in medicine,\\\" create sections for \\\"diagnostic applications,\\\" \\\"drug discovery,\\\" and \\\"ethical considerations.\\\"\n",
        "\n",
        "Summarize: Create a concise summary for each major theme. These summaries should capture the essence of the findings without getting lost in technical details, and they should be grounded in the extracted data from the knowledge base.\n",
        "\n",
        "2. Critical Review (Critic/Reflection Agent)\n",
        "\n",
        "Evaluate: Review the synthesized summaries and the extracted data.\n",
        "\n",
        "Check for:\n",
        "\n",
        "Accuracy: Are the findings correctly represented?\n",
        "\n",
        "Completeness: Are there any significant gaps in the information that need to be filled?\n",
        "\n",
        "Relevance: Does the information directly address the user's original query?\n",
        "\n",
        "Logical Flow: Does the synthesized information make sense as a cohesive whole?\n",
        "\n",
        "Revise: If the review finds any deficiencies, send a command back to the Orchestration Agent to re-execute specific steps of the plan (e.g., \\\"Conduct a more specific search for ethical challenges of AI in medicine\\\").\n",
        "\n",
        "Phase 4: Final Report Generation\n",
        "1. Structure the Output (Report Generator Agent)\n",
        "\n",
        "Format: Assemble the validated and synthesized information into a final report. The report should have a clear structure:\n",
        "\n",
        "Introduction: Briefly state the purpose of the report based on the user's query.\n",
        "\n",
        "Main Body: Present the findings, organized by the themes identified in the synthesis phase. Use clear headings and subheadings.\n",
        "\n",
        "Conclusion: Summarize the key takeaways and provide a final synthesis of the research.\n",
        "\n",
        "2. Final Review and Delivery\n",
        "\n",
        "Final Check: Do a final review of the report for clarity, grammar, and overall quality.\n",
        "\n",
        "Deliver: Send the final report to the user through the designated output channel.\"\"\"\n",
        "        for message in messages:\n",
        "            if message[\"role\"] == \"system\":\n",
        "                instructions += message[\"content\"]\n",
        "        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
        "        return graph\n",
        "\n",
        "    def convert_messages(messages):\n",
        "        converted_messages = []\n",
        "        for message in messages:\n",
        "            if (message[\"role\"] == \"user\"):\n",
        "                converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
        "            elif (message[\"role\"] == \"assistant\"):\n",
        "                converted_messages.append(AIMessage(content=message[\"content\"]))\n",
        "        return converted_messages\n",
        "\n",
        "    def generate(context):\n",
        "        payload = context.get_json()\n",
        "        messages = payload.get(\"messages\")\n",
        "        inner_credentials = {\n",
        "            \"url\": service_url,\n",
        "            \"token\": context.get_token()\n",
        "        }\n",
        "\n",
        "        inner_client = APIClient(inner_credentials)\n",
        "        model = create_chat_model(inner_client)\n",
        "        tools = create_tools(inner_client, context)\n",
        "        agent = create_agent(model, tools, messages)\n",
        "\n",
        "        generated_response = agent.invoke(\n",
        "            { \"messages\": convert_messages(messages) },\n",
        "            { \"configurable\": { \"thread_id\": \"42\" } }\n",
        "        )\n",
        "\n",
        "        last_message = generated_response[\"messages\"][-1]\n",
        "        generated_response = last_message.content\n",
        "\n",
        "        execute_response = {\n",
        "            \"headers\": {\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            \"body\": {\n",
        "                \"choices\": [{\n",
        "                    \"index\": 0,\n",
        "                    \"message\": {\n",
        "                       \"role\": \"assistant\",\n",
        "                       \"content\": generated_response\n",
        "                    }\n",
        "                }]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return execute_response\n",
        "\n",
        "    def generate_stream(context):\n",
        "        print(\"Generate stream\", flush=True)\n",
        "        payload = context.get_json()\n",
        "        headers = context.get_headers()\n",
        "        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n",
        "        messages = payload.get(\"messages\")\n",
        "        inner_credentials = {\n",
        "            \"url\": service_url,\n",
        "            \"token\": context.get_token()\n",
        "        }\n",
        "        inner_client = APIClient(inner_credentials)\n",
        "        model = create_chat_model(inner_client)\n",
        "        tools = create_tools(inner_client, context)\n",
        "        agent = create_agent(model, tools, messages)\n",
        "\n",
        "        response_stream = agent.stream(\n",
        "            { \"messages\": messages },\n",
        "            { \"configurable\": { \"thread_id\": \"42\" } },\n",
        "            stream_mode=[\"updates\", \"messages\"]\n",
        "        )\n",
        "\n",
        "        for chunk in response_stream:\n",
        "            chunk_type = chunk[0]\n",
        "            finish_reason = \"\"\n",
        "            usage = None\n",
        "            if (chunk_type == \"messages\"):\n",
        "                message_object = chunk[1][0]\n",
        "                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n",
        "                    message = {\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": message_object.content\n",
        "                    }\n",
        "                else:\n",
        "                    continue\n",
        "            elif (chunk_type == \"updates\"):\n",
        "                update = chunk[1]\n",
        "                if (\"agent\" in update):\n",
        "                    agent = update[\"agent\"]\n",
        "                    agent_result = agent[\"messages\"][0]\n",
        "                    if (agent_result.additional_kwargs):\n",
        "                        kwargs = agent[\"messages\"][0].additional_kwargs\n",
        "                        tool_call = kwargs[\"tool_calls\"][0]\n",
        "                        if (is_assistant):\n",
        "                            message = {\n",
        "                                \"role\": \"assistant\",\n",
        "                                \"step_details\": {\n",
        "                                    \"type\": \"tool_calls\",\n",
        "                                    \"tool_calls\": [\n",
        "                                        {\n",
        "                                            \"id\": tool_call[\"id\"],\n",
        "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
        "                                            \"args\": tool_call[\"function\"][\"arguments\"]\n",
        "                                        }\n",
        "                                    ]\n",
        "                                }\n",
        "                            }\n",
        "                        else:\n",
        "                            message = {\n",
        "                                \"role\": \"assistant\",\n",
        "                                \"tool_calls\": [\n",
        "                                    {\n",
        "                                        \"id\": tool_call[\"id\"],\n",
        "                                        \"type\": \"function\",\n",
        "                                        \"function\": {\n",
        "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
        "                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n",
        "                                        }\n",
        "                                    }\n",
        "                                ]\n",
        "                            }\n",
        "                    elif (agent_result.response_metadata):\n",
        "                        # Final update\n",
        "                        message = {\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"content\": agent_result.content\n",
        "                        }\n",
        "                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n",
        "                        if (finish_reason):\n",
        "                            message[\"content\"] = \"\"\n",
        "\n",
        "                        usage = {\n",
        "                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n",
        "                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n",
        "                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n",
        "                        }\n",
        "                elif (\"tools\" in update):\n",
        "                    tools = update[\"tools\"]\n",
        "                    tool_result = tools[\"messages\"][0]\n",
        "                    if (is_assistant):\n",
        "                        message = {\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"step_details\": {\n",
        "                                \"type\": \"tool_response\",\n",
        "                                \"id\": tool_result.id,\n",
        "                                \"tool_call_id\": tool_result.tool_call_id,\n",
        "                                \"name\": tool_result.name,\n",
        "                                \"content\": tool_result.content\n",
        "                            }\n",
        "                        }\n",
        "                    else:\n",
        "                        message = {\n",
        "                            \"role\": \"tool\",\n",
        "                            \"id\": tool_result.id,\n",
        "                            \"tool_call_id\": tool_result.tool_call_id,\n",
        "                            \"name\": tool_result.name,\n",
        "                            \"content\": tool_result.content\n",
        "                        }\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            chunk_response = {\n",
        "                \"choices\": [{\n",
        "                    \"index\": 0,\n",
        "                    \"delta\": message\n",
        "                }]\n",
        "            }\n",
        "            if (finish_reason):\n",
        "                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n",
        "            if (usage):\n",
        "                chunk_response[\"usage\"] = usage\n",
        "            yield chunk_response\n",
        "\n",
        "    return generate, generate_stream\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_ibm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9NQIpWFj4pW",
        "outputId": "c0466509-2b44-4b01-cff1-7c08665b3ce4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_ibm in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: ibm-watsonx-ai<2.0.0,>=1.3.28 in /usr/local/lib/python3.11/dist-packages (from langchain_ibm) (1.3.32)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.39 in /usr/local/lib/python3.11/dist-packages (from langchain_ibm) (0.3.72)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.32.4)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.5.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2025.7.14)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (25.0)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.15.0,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.14.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (5.5.2)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (4.14.1)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain_ibm) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (0.16.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.14.3 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.14.3)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.14.3 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.14.3)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.9.0.post0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain_ibm) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (3.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.28->langchain_ibm) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c13f0784",
        "outputId": "72701755-abbd-469f-b5b1-f22af99b067e"
      },
      "source": [
        "!pip install langgraph"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.3-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.3-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.3 langgraph-sdk-0.2.0 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "e3gUSyPJi9ND"
      },
      "cell_type": "code",
      "source": [
        "# Initialize AI Service function locally\n",
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "\n",
        "streaming = False\n",
        "findex = 1 if streaming else 0\n",
        "local_function = gen_ai_service(context,  space_id=space_id)[findex]\n",
        "messages = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_zaecEexi9ND"
      },
      "cell_type": "code",
      "source": [
        "local_question = \"Summarize the latest research on sustainable energy.\"\n",
        "messages.append({ \"role\" : \"user\", \"content\": local_question })\n",
        "context = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n",
        "response = local_function(context)\n",
        "result = ''\n",
        "if (streaming):\n",
        "    for chunk in response:\n",
        "        print(chunk, end=\"\\n\\n\", flush=True)\n",
        "else:\n",
        "    print(response)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbUJbQMVi9NE"
      },
      "cell_type": "code",
      "source": [
        "# Look up software specification for the AI service\n",
        "software_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\n",
        "software_spec_id = \"\"\n",
        "\n",
        "try:\n",
        "    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
        "except:\n",
        "    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AorAf5pMi9NE"
      },
      "cell_type": "code",
      "source": [
        "# Define the request and response schemas for the AI service\n",
        "request_schema = {\n",
        "    \"application/json\": {\n",
        "        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"messages\": {\n",
        "                \"title\": \"The messages for this chat session.\",\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"role\": {\n",
        "                            \"title\": \"The role of the message author.\",\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"user\",\"assistant\"]\n",
        "                        },\n",
        "                        \"content\": {\n",
        "                            \"title\": \"The contents of the message.\",\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"role\",\"content\"]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"messages\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "response_schema = {\n",
        "    \"application/json\": {\n",
        "        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f5CB6LzPi9NE"
      },
      "cell_type": "code",
      "source": [
        "# Store the AI service in the repository\n",
        "ai_service_metadata = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Agent for research\",\n",
        "    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n",
        "    client.repository.AIServiceMetaNames.CUSTOM: {},\n",
        "    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n",
        "    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n",
        "    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n",
        "}\n",
        "\n",
        "ai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXkd6zyFi9NE"
      },
      "cell_type": "code",
      "source": [
        "# Get the AI Service ID\n",
        "\n",
        "ai_service_id = client.repository.get_ai_service_id(ai_service_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_pwUgtMi9NE"
      },
      "cell_type": "code",
      "source": [
        "# Deploy the stored AI Service\n",
        "deployment_custom = {\n",
        "    \"avatar_icon\": \"DecisionTree\",\n",
        "    \"avatar_color\": \"backgroundBrand\",\n",
        "    \"placeholder_image\": \"placeholder2.png\",\n",
        "    \"sample_questions\": [\"Summarize the latest research on sustainable energy.\",\"Recent paper on the Agriculture development\"]\n",
        "}\n",
        "deployment_metadata = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"Agent for research\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n",
        "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"AI research assistant agent for quick insights, summaries, and trend discovery.\",\n",
        "    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n",
        "}\n",
        "\n",
        "function_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBKELnAhi9NF"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Test AI Service"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8xVxS5i9NF",
        "outputId": "4097dc8a-07e6-44a2-89e5-23b16e8fb769"
      },
      "cell_type": "code",
      "source": [
        "# Get the ID of the AI Service deployment just created\n",
        "\n",
        "deployment_id = client.deployments.get_id(function_deployment_details)\n",
        "print(deployment_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01da35c1-d044-438b-9b1f-18306c72c530\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uj36sg5ri9NF"
      },
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "remote_question = \"Summarize the latest research on sustainable energy.\"\n",
        "messages.append({ \"role\" : \"user\", \"content\": remote_question })\n",
        "payload = { \"messages\": messages }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qXeqUvoi9NF",
        "outputId": "d9558ed4-6000-4b3b-bb6e-fcbd4d975127"
      },
      "cell_type": "code",
      "source": [
        "result = client.deployments.run_ai_service(deployment_id, payload)\n",
        "if \"error\" in result:\n",
        "    print(result[\"error\"])\n",
        "else:\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'choices': [{'index': 0, 'message': {'content': 'The latest research on sustainable energy, from 2020 to the present, has seen significant advancements in various areas:\\n\\n1. **Smart Grids**: In 2022, a study simulated and analyzed \"transactive energy mechanisms\" to engage the large-scale deployment of flexible distributed energy resources (DERs), such as air conditioners, water heaters, batteries, and electric vehicles, in the operation of the electric power system.\\n\\n2. **Super Grids**: Researchers proposed a novel strategy in 2022 to create a global sustainable interconnected energy system based on deep-ocean-compressed hydrogen transportation.\\n\\n3. **Microgrids and Off-the-Grid Solutions**: A method for integrating multiple energy storage systems and distributed energy resources without dedicated communication or control systems was described in 2022. This approach could make microgrids more accessible and affordable, especially in areas where they are most needed, such as during power outages or after disasters.\\n\\n4. **Solar Power**:\\n   - **Perovskite Solar Cells**: Efficiency has dramatically increased from 3.8% in 2009 to 25.2% in single-junction architectures and 29.1% in tandem cells by 2020, surpassing the maximum efficiency of single-junction silicon solar cells.\\n   - In 2021, scientists demonstrated that adding a layer of perovskite crystals on top of textured or planar silicon could enhance tandem solar cell performance up to 26% power conversion efficiency.\\n   - A low-cost method to boost solar cell efficiency using an organic-based ionic solid in perovskites was reported in 2021.\\n   - The first industrial commercial production line of perovskite solar panels, using an inkjet printing procedure, was launched in Poland in 2021.\\n   - A comprehensive database and analysis tool for perovskite solar cells, integrating over 15,000 publications and device-data on more than 42,400 photovoltaic devices, was developed in 2021.\\n\\n5. **Other Developments**:\\n   - Researchers have been addressing the stability and long-term reliability of perovskite solar cells by using \"molecular glue\" (2021).\\n   - A global assessment of solar photovoltaic modules recycling approaches was published in 2020, recommending research to reduce recycling costs and environmental impacts while maximizing material recovery.\\n   - Both-sides-contacted silicon solar cells with conversion efficiencies of 26% and above were prototyped and designed in 2021.\\n\\nThis summary highlights the progress in sustainable energy research, focusing on smart grids, super grids, microgrids, and advancements in solar technology, particularly perovskite solar cells.', 'role': 'assistant'}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b0d5471",
        "outputId": "8b15cbc1-6868-44d1-dc33-37ee1bf918e7"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "6d0fdc6a",
        "outputId": "a0edc6bd-efdb-4c25-e641-6618cd8f77ba"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def query_agent(question):\n",
        "    \"\"\"Sends a question to the deployed AI service and returns the response.\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": question}]\n",
        "    payload = {\"messages\": messages}\n",
        "\n",
        "    result = client.deployments.run_ai_service(deployment_id, payload)\n",
        "\n",
        "    if \"error\" in result:\n",
        "        return f\"An error occurred: {result['error']}\"\n",
        "    elif \"choices\" in result and result[\"choices\"]:\n",
        "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return \"Sorry, I could not get a valid response from the service.\"\n",
        "\n",
        "# Create and launch the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=query_agent,\n",
        "    inputs=gr.Textbox(lines=5, label=\"Your Question\",\n",
        "    placeholder=\"e.g., Summarize the latest research on sustainable energy.\"),\n",
        "    outputs=gr.Textbox(label=\"Agent's Response\"),\n",
        "    title=\"Agent for Research UI\",\n",
        "    description=\"Interact with the deployed AI research agent using this interface.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5fe00d107432e41f8d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5fe00d107432e41f8d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQhHOLdSxhxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10",
      "language": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}